{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# **IMPORT LIBRERIE**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "tf.executing_eagerly() \n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "source": [
    "# **APRE IL FILE CON LABELS E SALVA I VALORI IN UN DIZIONARIO**\n",
    "Il dizionario ha come chiave il nome del file e valore il valore della label"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_labels(filename,train=True):\n",
    "  csv_file = open(filename)\n",
    "  reader = csv.reader(csv_file, delimiter=',', quotechar='|')\n",
    "  rows = list(reader)\n",
    "  labels_dict = {}\n",
    "\n",
    "  y = []\n",
    "  for row in rows:\n",
    "    value = int(row[1])\n",
    "    labels_dict[row[0]]=value-1\n",
    "    y.append(value)\n",
    "\n",
    "  if train:\n",
    "    NUM_CLASSES = np.unique(y).shape[0] \n",
    "    return labels_dict,NUM_CLASSES\n",
    "  else:\n",
    "    return labels_dict,None\n",
    "  \n",
    "\n",
    "train_labels_dict,NUM_CLASSES = read_labels('/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/train_labels.csv',train = True)\n",
    "valid_labels_dict,_ = read_labels('/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/valid_labels.csv',train = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legge il file contentnente i pesi per ogni classe e li salva in un dizionario\n",
    "csv_file = open('/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/weights.csv')\n",
    "reader = csv.reader(csv_file, delimiter=',', quotechar='|')\n",
    "rows = list(reader)\n",
    "\n",
    "class_weights = {}\n",
    "\n",
    "for i in range(len(rows)):\n",
    "  class_weights[int(rows[i][0])] = float(rows[i][1])\n"
   ]
  },
  {
   "source": [
    "# **CLASSE FACE DETECTOR**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFile = \"/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "configFile = \"/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/deploy.prototxt\"\n",
    "\n",
    "class FaceDetector:\n",
    "    net = None\n",
    "    def __init__(self, min_confidence=0.5):\n",
    "        print (\"FaceDetector -> init\")\n",
    "        self.net = cv.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "        self.min_confidence = min_confidence\n",
    "        print (\"FaceDetector -> init ok\")\n",
    "    \n",
    "    def detect(self, image):\n",
    "        blob = cv.dnn.blobFromImage(image, 1.0, (128, 128), [106, 121, 150], False, False)\n",
    "        frameHeight, frameWidth, channels = image.shape\n",
    "        self.net.setInput(blob)\n",
    "        detections = self.net.forward()\n",
    "        faces_result=[]\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > self.min_confidence:\n",
    "                x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "                y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "                x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "                y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "                f = (x1,y1, x2-x1, y2-y1)\n",
    "                if f[2]>1 and f[3]>1:\n",
    "                    faces_result.append({\n",
    "                        'roi': f,\n",
    "                        'type': 'face',\n",
    "                        'img': image[f[1]:f[1]+f[3], f[0]:f[0]+f[2]],\n",
    "                        'confidence' : confidence\n",
    "                    })\n",
    "        return faces_result\n",
    "    \n",
    "    def __del__(self):\n",
    "        print (\"FaceDetector -> bye\")\n",
    "\n",
    "\n",
    "def findRelevantFace(objs, W,H):\n",
    "    mindistcenter = None\n",
    "    minobj = None\n",
    "    for o in objs:\n",
    "        cx = o['roi'][0] + (o['roi'][2]/2)\n",
    "        cy = o['roi'][1] + (o['roi'][3]/2)\n",
    "        distcenter = (cx-(W/2))**2 + (cy-(H/2))**2\n",
    "        if mindistcenter is None or distcenter < mindistcenter:\n",
    "            mindistcenter = distcenter\n",
    "            minobj = o\n",
    "    return minobj"
   ]
  },
  {
   "source": [
    "# **FUNZIONI PREPROCESSING DATASET**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import dlib\n",
    "import cv2 as cv\n",
    "from random import getrandbits,randint\n",
    "from imutils import rotate\n",
    "\n",
    "\n",
    "\n",
    "size = (100,100,3)\n",
    "\n",
    "def show_image(arr,norm=True):\n",
    "  \"\"\"Mostra un'immagine\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  arr : np.ndarray\n",
    "      Immagine da visualizzare\n",
    "  norm : boolean, optional\n",
    "      Booleano che indica se l'immagine che viene passata è stata normalizzata nel range [0,1]\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  None\n",
    "  \"\"\"\n",
    "  if norm:\n",
    "    arr = arr*255\n",
    "  imdata=arr.astype('uint8')\n",
    "  imdata=np.flip(imdata,-1)\n",
    "  img=Image.fromarray(imdata)\n",
    "  \n",
    "  display(img)\n",
    "\n",
    "  \n",
    "\n",
    "def preprocessing(img,label,resize=True,size=None,augment=False):\n",
    "  \"\"\"Effettua il preprocessing dell'immagine\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  img : np.ndarray\n",
    "      L'immagine da preprocessare\n",
    "  label: int\n",
    "      Label associata all'immagine\n",
    "  resize: bool, optional\n",
    "      Se true effettua il resize dell'immagine \n",
    "  size: tuple, optional\n",
    "      Se resize = True, effettua il resize della dimensione specificata\n",
    "\n",
    "  Returns\n",
    "  -------\n",
    "  tf.Tensor\n",
    "      L'immagine preprocessata sotto forma di tensore\n",
    "  \"\"\"\n",
    "  if resize:\n",
    "    img = cv.resize(img,(size,size))\n",
    "  \n",
    "  #applica il clahe\n",
    "  lab = cv.cvtColor(img, cv.COLOR_BGR2LAB)\n",
    "  lab_planes = cv.split(lab)\n",
    "  lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "  lab = cv.merge(lab_planes)\n",
    "  img = cv.cvtColor(lab, cv.COLOR_LAB2BGR)\n",
    "  if augment:\n",
    "    img = augmentation(img)\n",
    "  else:\n",
    "    img = img.astype(np.float32)\n",
    "    img = img/255.0\n",
    "    img = tf.convert_to_tensor(img,dtype=tf.float32)\n",
    "  return img\n",
    "\n",
    "\n",
    "def augmentation(img):\n",
    "  \"\"\"Applica la data augmentation sull'immagine \n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  img : np.ndarray\n",
    "        immagine su cui applicare la data augmentation\n",
    "\n",
    "  Returns\n",
    "  tf.Tensor\n",
    "    Tensore che contiene l'immagine\n",
    "  \"\"\"\n",
    "    #random flip orizzontale e verticale\n",
    "  if bool(getrandbits(1)):\n",
    "    img = cv.flip(img,1)\n",
    "\n",
    "  image = tf.convert_to_tensor(img,tf.float32)\n",
    "  #random brightness\n",
    "  image = tf.image.random_brightness(image,max_delta=0.5)\n",
    "  #random contrast\n",
    "  image = tf.image.random_contrast(image,lower=0.1,upper=1)\n",
    "  #random saturation\n",
    "  image = tf.image.random_saturation(image, lower=0.1,upper=1)\n",
    "  #normalizza nel range [0,1]\n",
    "  image = tf.cast(image,tf.float32)/255.0\n",
    "\n",
    "  return image\n",
    "\n",
    "\n",
    "def align_and_preprocess(img,label,augment=True):\n",
    "  \"\"\"\n",
    "     Chiama la funzione detect and align utilizzando la funzione wrapper di tensorflow py_function\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  img : ndarray\n",
    "        Immagine da preprocessare\n",
    "  label : float\n",
    "        label associata all'imamgine\n",
    "  augment : bool optional\n",
    "        se true, applica la data augmentation\n",
    "\n",
    "  Returns\n",
    "  tuple\n",
    "    Tupla che contiene l'immagine e la label processate\n",
    "  \"\"\"\n",
    "  image = tf.py_function(detect_and_align,[img,label,size,augment],tf.float32)\n",
    "\n",
    "  #if train:\n",
    "  #  labels_dict = train_labels_dict\n",
    "  #else:\n",
    "  #  labels_dict = valid_labels_dict \n",
    "\n",
    "  #label = tf.py_function(map_labels,[sample['file_name'],sample['label'],labels_dict],tf.float32)\n",
    "  #label = tf.reshape(label, [NUM_CLASSES])\n",
    "  return image, label\n",
    "\n",
    "\n",
    "def map_labels(filename):\n",
    "  \"\"\"Effettua il mapping tra un campione del dataset e la label necessaria\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename : tf.Tensor\n",
    "        Tensore che contiene il nome del file\n",
    "  label : tf.Tensor\n",
    "        Tensore che contine la label originaria del dataset\n",
    "\n",
    "  Returns\n",
    "  float\n",
    "    Label da utilizzare. Se non esiste un mapping filename labels_dict ritorna 255.0\n",
    "  \"\"\"\n",
    "\n",
    "  filename = filename.numpy().decode('UTF-8')\n",
    "  if filename in labels_dict:\n",
    "    return tf.keras.utils.to_categorical(labels_dict[filename],NUM_CLASSES)\n",
    "  else:\n",
    "    return tf.fill([NUM_CLASSES],255.0)\n",
    "  \n",
    "@tf.function\n",
    "def filter_labels(img,label):\n",
    "  \"\"\"Filtra dal dataset tutti i campioni a cui non è associata una label. I file che non hanno label sono mappati con la label 255.0\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  filename : tf.Tensor\n",
    "        Tensore che contiene l'immagine\n",
    "  label : tf.Tensor\n",
    "        Tensore che contine la label\n",
    "\n",
    "  Returns\n",
    "  bool\n",
    "    True se label != 255, False altrimenti\n",
    "  \"\"\"\n",
    "  label = tf.cast(label,tf.uint8)\n",
    "\n",
    "  a = mask_label.__eq__(label)\n",
    "  a = tf.reduce_all(a)\n",
    "  return not a\n",
    "\n",
    "def findRelevantFace(objs, W,H):\n",
    "  \"\"\"Trova il volto principale tra i volti trovati nella face detection\n",
    "  Parameters\n",
    "  ----------\n",
    "  objs : tf.Tensor\n",
    "        lista di dizionari, ogni elemento della lista contiene informazioni su un volto rilevato\n",
    "  W : tf.Tensor\n",
    "        larghezza dell'immagine originale\n",
    "  H : int\n",
    "        lunghezza dell'immagine originale\n",
    "  Returns\n",
    "  bool\n",
    "    True se label != 255, False altrimenti\n",
    "\n",
    "  \"\"\"\n",
    "  mindistcenter = None\n",
    "  minobj = None\n",
    "  for o in objs:\n",
    "      cx = o['roi'][0] + (o['roi'][2]/2)\n",
    "      cy = o['roi'][1] + (o['roi'][3]/2)\n",
    "      distcenter = (cx-(W/2))**2 + (cy-(H/2))**2\n",
    "      if mindistcenter is None or distcenter < mindistcenter:\n",
    "          mindistcenter = distcenter\n",
    "          minobj = o\n",
    "  return minobj\n",
    "\n",
    "def detect_and_align(img,label,size,augment):\n",
    "  \"\"\"Effettua la detection della faccia nell'immagine e allinea il volto.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  img : tf.Tensor\n",
    "        Tensore che contiene l'immagine\n",
    "  label : tf.Tensor\n",
    "        Tensore che contine la label\n",
    "  size : tuple\n",
    "        Dimensione desiderata dell'immagine preprocessata\n",
    "  augment : bool\n",
    "        Se true, applica la data augmentation\n",
    "  Returns\n",
    "  Tf.Tensor\n",
    "    Tensore che contine l'immagine preprocessata\n",
    "  \"\"\"\n",
    "  resize= False\n",
    "  img_array = img.numpy()\n",
    "  #img_array = img.copy()\n",
    "  detected_imgs = face_det.detect(img_array)\n",
    "  if len(detected_imgs) != 0:\n",
    "      relevant = findRelevantFace(detected_imgs,img_array.shape[1],img_array.shape[0])\n",
    "      roi = relevant['roi']\n",
    "      rect = dlib.rectangle(roi[0],roi[1],roi[0]+roi[2],roi[1]+roi[3])\n",
    "      face = sp(img_array, rect)\n",
    "      img_array = dlib.get_face_chip(img_array, face, size=size[0])\n",
    "  else:\n",
    "      resize = True\n",
    "  return preprocessing(img_array,label,resize,size[0],augment)\n",
    "\n",
    "\n",
    "def preprocess_labels(sample):\n",
    "  \"\"\"Funzione che effettua il preprocessing delle labels\n",
    "  chiama la funzione map labels che associa al campione la corrispondente label presente nel file csv\n",
    "  Parameters\n",
    "  ----------\n",
    "  sample: dict\n",
    "    dizionario contenente il campione su cui effettuare il preproscessing della label\n",
    "  Returns\n",
    "  tuple\n",
    "    tupla che contiene l'immagine e la label preprocessata\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  label = tf.py_function(map_labels,[sample['file_name']],tf.float32)\n",
    "  label = tf.reshape(label, [NUM_CLASSES])\n",
    "  #sample['label'] = label\n",
    "\n",
    "  return sample['image'],label\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "clahe = cv.createCLAHE(2,(3,3))\n",
    "face_det = FaceDetector()\n",
    "predictor_path = \"/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/data/shape_predictor_68_face_landmarks.dat\"\n",
    "sp = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "mask_label = tf.fill([NUM_CLASSES],255)\n",
    "mask_label = tf.cast(mask_label,tf.uint8)\n"
   ]
  },
  {
   "source": [
    "# **APRE IL DATASET, SI EFFETTUA IL PREPROCESSING E SPLIT TRAIN VALIDATION**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from random import randint \n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "ds = tfds.load(\n",
    "    name='vgg_face2',\n",
    "    split='train',\n",
    "    data_dir='/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/vggface2',\n",
    "    shuffle_files = True,\n",
    "    as_supervised = False\n",
    ")\n",
    "LENGTH = len(ds)\n",
    "\n",
    "labels_dict = train_labels_dict\n",
    "\n",
    "\n",
    "\n",
    "train_ds = ds\n",
    "train_ds = train_ds.map(preprocess_labels,num_parallel_calls=AUTOTUNE)\n",
    "train_ds = train_ds.filter(filter_labels)\n",
    "train_ds = train_ds.map(align_and_preprocess,num_parallel_calls=1)\n",
    "train_ds = train_ds.batch(BATCH_SIZE).cache('/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/train').prefetch(AUTOTUNE)\n",
    "\n",
    "labels_dict = valid_labels_dict\n",
    "valid_ds = ds\n",
    "\n",
    "valid_ds = valid_ds.map(preprocess_labels,num_parallel_calls=AUTOTUNE)\n",
    "valid_ds = valid_ds.filter(filter_labels)\n",
    "valid_ds = valid_ds.map(align_and_preprocess,num_parallel_calls=1)\n",
    "valid_ds = valid_ds.batch(BATCH_SIZE).cache('/home/paolo/ComputerSync/Università/ProgettoAgeEstimation/AgeEstimation/valid').prefetch(AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# **MAE METRICS**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def mae(y_true,y_pred):\n",
    "  return K.mean(K.abs(K.argmax(y_true,-1)-K.argmax(y_pred,-1)),0)\n"
   ]
  },
  {
   "source": [
    "# **DEFINIZIONE MODELLO**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras_applications\n",
    "!pip install image-classifiers==1.0.0b1\n",
    "from classification_models.keras import Classifiers\n",
    "np.random.seed(23)\n",
    "os.environ['PYTHONHASHSEED'] = '5'\n",
    "random.seed(666)\n",
    "tf.random.set_seed(666)\n",
    "tf.compat.v1.reset_default_graph()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "size = (100,100,3)\n",
    "\n",
    "\n",
    "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "model = ResNet18(size, weights=None,classes=NUM_CLASSES,classifier_activation=\"softmax\")"
   ]
  },
  {
   "source": [
    "# **CALLBACKS**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIDUCE IL LEARNING RATE SE LA LOSS SI FERMA\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "#FERMA IL TRAINING SE LA VALIDATION LOSS RESTA FERMA PER TROPPE EPOCHE\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.001,\n",
    "    patience=10,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "#SALVA IL MODELLO DOPO OGNI EPOCA\n",
    "model_check = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/temp_model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\"\n",
    "    )\n",
    "\n",
    "\n",
    "callbacks = [model_check,reduce_lr,early_stop]\n"
   ]
  },
  {
   "source": [
    "# **FIT**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "import pandas as pd\n",
    "\n",
    "epochs = {\n",
    "    0:50,\n",
    "    1:100\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "  EPOCHS = epochs[i]\n",
    "\n",
    "  model_check = tf.keras.callbacks.ModelCheckpoint(\"/content/drive/MyDrive/model%s.h5\" % (i),\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode=\"auto\"\n",
    "    )\n",
    "\n",
    "  if i == 0:\n",
    "    opt = DemonAdam(637*EPOCHS)\n",
    "    callbacks = [model_check,reduce_lr]\n",
    "  else:\n",
    "    opt = DemonSGD(EPOCHS*637,learning_rate=0.01,momentum=0.9,nesterov=True)\n",
    "    callbacks = [model_check,reduce_lr,lr_scheduler]\n",
    "  \n",
    "  \n",
    "\n",
    "  model.compile(\n",
    "      optimizer=opt,\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.15),\n",
    "      metrics=[mae]\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "  history = model.fit(\n",
    "      train_ds,\n",
    "      epochs=EPOCHS,\n",
    "      batch_size=None,\n",
    "      validation_data=valid_ds,\n",
    "      callbacks=callbacks,\n",
    "      class_weight=class_weights,\n",
    "      use_multiprocessing=True,\n",
    "      shuffle=False,\n",
    "      workers=cpu_count(),\n",
    "      verbose=1,\n",
    "      max_queue_size=BATCH_SIZE,\n",
    "      initial_epoch=0\n",
    "  )\n",
    "\n",
    "\n",
    "  # convert the history.history dict to a pandas DataFrame:     \n",
    "  hist_df = pd.DataFrame(history.history) \n",
    "  PATH = '/content/drive/MyDrive/model%s.csv' % (EPOCHS)\n",
    "  hist_csv_file = PATH\n",
    "  with open(hist_csv_file, mode='w') as f:\n",
    "    hist_df.to_csv(f)\n",
    "\n"
   ]
  },
  {
   "source": [
    "# **SALVA IL MODELLO SU FILE**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/content/drive/MyDrive/model.h5')"
   ]
  },
  {
   "source": [
    "# ** EVALUATION SUL VALIDATION SET E MATRICE DI CONFUSIONE**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_true = []\n",
    "ds = valid_ds.unbatch()\n",
    "for el in ds:\n",
    "    y_true.append(np.argmax(el[1]))\n",
    "\n",
    "print(\"Evaluation\")\n",
    "print(model.evaluate(valid_ds))\n",
    "\n",
    "y_pred = model.predict(valid_ds)\n",
    "argmax = np.argmax(y_pred,-1)\n",
    "conf_mat = confusion_matrix(y_true,argmax)\n",
    "sns.heatmap(conf_mat, annot=False,cmap=plt.cm.Reds)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ]
}